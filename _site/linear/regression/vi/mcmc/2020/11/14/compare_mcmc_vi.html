
<!DOCTYPE html>
<html lang="en">
head>
 <meta charset="utf-8">
 <meta name="viewport" content="width=device-width,initial-scale=1">
 <title> Malte Tölle </title>
 <link href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab:300|Roboto:500" rel="stylesheet">
 <link rel="stylesheet" href="/assets/css/styles.css">
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
 <script src="/assets/js/jquery-cookie/src/jquery.cookie.js" type="text/javascript"></script>
 <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
    "HTML-CSS": {
     styles: {

       ".MJXc-display": {
         // "background-color": "#FFFF88",
         // "color":   "#CC0000",
         // "border":  "1px solid #CC0000",
         // "padding": "1px 3px",
         // "font-family": "serif",
         // "font-style": "normal",
         "font-size":  "10%"
       },

       ".MathJax_Preview": {color: "#888888"},

     }
    },
     extensions: [
       "MathMenu.js",
       "MathZoom.js",
       "AssistiveMML.js",
       "a11y/accessibility-menu.js"
     ],
     jax: ["input/TeX", "output/CommonHTML"],
     TeX: {
       extensions: [
         "AMSmath.js",
         "AMSsymbols.js",
         "noErrors.js",
         "noUndefined.js",
       ]
     }

   });
 </script>
 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
 </script>
</head>

  <!--<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Linear Regression with Variational Inference and Markov Chain Monte Carlo Sampling | Malte Tölle</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Linear Regression with Variational Inference and Markov Chain Monte Carlo Sampling" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In my blog post about Bayesian linear regression I go more in depth into the topic of linear regression in general. You might want to check it out, if you are unfamiliar with it. Here we will only review the most basic intuitions." />
<meta property="og:description" content="In my blog post about Bayesian linear regression I go more in depth into the topic of linear regression in general. You might want to check it out, if you are unfamiliar with it. Here we will only review the most basic intuitions." />
<link rel="canonical" href="http://localhost:4000/linear/regression/vi/mcmc/2020/11/14/compare_mcmc_vi.html" />
<meta property="og:url" content="http://localhost:4000/linear/regression/vi/mcmc/2020/11/14/compare_mcmc_vi.html" />
<meta property="og:site_name" content="Malte Tölle" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-14T15:47:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Linear Regression with Variational Inference and Markov Chain Monte Carlo Sampling" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/linear/regression/vi/mcmc/2020/11/14/compare_mcmc_vi.html"},"url":"http://localhost:4000/linear/regression/vi/mcmc/2020/11/14/compare_mcmc_vi.html","headline":"Linear Regression with Variational Inference and Markov Chain Monte Carlo Sampling","dateModified":"2020-11-14T15:47:00+01:00","datePublished":"2020-11-14T15:47:00+01:00","description":"In my blog post about Bayesian linear regression I go more in depth into the topic of linear regression in general. You might want to check it out, if you are unfamiliar with it. Here we will only review the most basic intuitions.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Malte Tölle" /></head>
-->

  <body><div class="header">
 <div class="nav-click header-title-div">
 <a href="#intro" class="header-title"> Malte Tölle </a> </div>
 <div class="nav-bar nav-click">
   <a href="#pubs">Pubs</a>
   <a href="#posts">Blog</a>
   <a href="/contact">Contact</a>
 </div>
</div>
<main class="page-content" aria-label="Content">
     <div class="cookie-blocker"></div>
     <div class="wrapper">
      <div class="content">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Linear Regression with Variational Inference and Markov Chain Monte Carlo Sampling</h1>
    <p class="post-meta"><time class="dt-published" datetime="2020-11-14T15:47:00+01:00" itemprop="datePublished">
        Nov 14, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In my blog post about Bayesian linear regression I go more in depth into the topic of linear regression in general. You might want to check it out, if you are unfamiliar with it. Here we will only review the most basic intuitions.</p>

<p>Given a dataset \(\mathcal{D}=\{x_i,y_i\}\) and a model with parameters \(\boldsymbol{\theta}\) we want to find the best estimate for the true value for \(y\):</p>

\[\hat{y} = \theta_0 + \theta_1 x=\boldsymbol{\theta}^T\mathbf{x} ~,\]

<p>where we defined \(x_0=1\) and \(\hat{y}\) denotes the output of our model. Since all real world data is corrupted or distorted by noise coming from different sources (e.g. limitations in measurement tools), the true observations are pertubed with noise \(\epsilon\), which is assumed to be a Gaussian with zero mean and variance \(\sigma^2\):</p>

\[y_i=\boldsymbol{\theta}^T\mathbf{x}_i + \epsilon_i \quad \textrm{with} \quad \epsilon_i \sim \mathcal{N}(0,\sigma^2) ~.\]

<p>Thus, we can model each point with a Gaussian distribution</p>

\[p(y_i|\mathbf{x}_i,\boldsymbol{\theta},\sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}\exp \left\{-\frac{1}{2\sigma^2}(y_i - \boldsymbol{\theta}^T\mathbf{x}_i)^2 \right\} ~.\]

<p>Assuming i.i.d. data points the probability of all points called likelihood factorizes:</p>

\[p(\mathbf{y}|\mathbf{X},\boldsymbol{\theta},\sigma^2) = \prod_i p(y_i|\mathbf{x}_i,\boldsymbol{\theta},\sigma^2) = \sum_i \log p(y_i|\mathbf{x}_i,\boldsymbol{\theta},\sigma^2) ~.\]

<p>Derivating for \(\boldsymbol{\theta}\) and \(\sigma^2\) and setting the derivative to 0 yields the maximum likelihood estimate (MLE). In contrast to MLE variational inference (VI) and Markov chain Monte Carlo (MCMC) sampling provide measures for certainty in the proposed parameters by making use of Bayes’ theroem:</p>

\[p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)= \frac{p(\mathbf{y}|\mathbf{X},\boldsymbol{\theta},\sigma^2)p(\boldsymbol{\theta})}{p(\mathbf{y}|\mathbf{X},\sigma^2)} \\ \textrm{posterior} = \frac{\textrm{likelihood } \times \textrm{ prior}}{\textrm{evidence}} ~.\]

<p>While the likelihood is the one from above, we introduce three new terms here: the posterior, prior, and evidence. The likelihood is multiplied by a prior, a distribution over \(\boldsymbol{\theta}\), that quantifies our believe in the model parameters prior to any training. We can also express zero prior knowledge by using a uniform distribution or a fairly wide Gaussian, when we assume our parameters to have Gaussian distributions. When we have computed the product of likelihood and prior, the evidence normalizes that product to obtain a valid probability distribution. The evidence can be seen as probability for seeing that particular data. After we have performed these computations, we obtain the posterior: the probability distribution of the parameters after seeing data.
For a new data point \((\mathbf{x}_∗, y_*)\) the prediction of the model is obtained by considering
the predictions made using all possible parameter setting, weighted by their posterior
probability:</p>

\[p(y_*|\mathbf{x}_*,\mathbf{y},\mathbf{X},\sigma^2) = \int p(y_*|\mathbf{x}_*,\boldsymbol{\theta})p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)d\boldsymbol{\theta} ~.\]

<p>Problematically this integral becomes intractable for even small models that are non-linear, so that other techniques such as VI and MCMC sampling must be employed. Here we compare both methods for the linear case.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">()</span>

<span class="n">matplotlib</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'text.usetex'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'text.latex.preamble'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s">r'\usepackage{bm}'</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="generating-example-data">Generating example data</h3>
<p>\(y = \theta_0 + \theta_1 x + \epsilon = -1 + x + \epsilon \quad \textrm{with} \quad \epsilon \sim \mathcal{N}(0,0.15)\) .</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">))]).</span><span class="n">transpose</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">weights</span><span class="p">[:,</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]).</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">no_samples</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">no_samples</span><span class="p">)</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">std_noise</span> <span class="o">=</span> <span class="mf">1.2</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="n">y_noisy</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std_noise</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'true'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_noisy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/imgs/compare_mcmc_vi_files/compare_mcmc_vi_3_0.png" alt="png" /></p>

<h3 id="mcmc-sampling">MCMC Sampling</h3>

<p>One popular technique for approximating the intractable posterior is MCMC sampling, conrtary to other methods it makes no assumption concerning the form of the distribution, such as wether it can be approximated by a multivariate Gaussian.
They only assume the posterior \(p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)\) can be calculated up to normalization constant \(Z\) meaning \(p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)=\tilde{p}(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)/Z\), where \(Z\) denotes the evidence in our case.</p>

<p>In general, sampling methods try to find the expectation of some function \(\mathbf{f}_{\boldsymbol{\theta}}(\mathbf{x})\) w.r.t. the posterior distribution for the model parameter:</p>

\[\mathbb{E}(\mathbf{f}) = \int \mathbf{f}_{\boldsymbol{\theta}}(\mathbf{x}_*)p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)d\boldsymbol{\theta} ~.\]

<p>The integral in above equation is approximated using Monte Carlo sampling:</p>

\[\mathbb{E}(\mathbf{f}) = \frac{1}{M} \sum_{i=1}^M \mathbf{f}_{\boldsymbol{\theta}_i}(\mathbf{x}_i) \quad \textrm{where} \quad \boldsymbol{\theta}_i \sim p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2) ~.\]

<p>Similar, the variance can be denoted by</p>

\[\textrm{Var}[\mathbf{f}] = \frac{1}{M} \mathbb{E}[(\mathbf{f}-\mathbb{E}[\mathbf{f}])^2] ~,\]

<p>if the generated samples from the posterior \(\boldsymbol{\theta}_i\) are independent. For complicated posterior distributions this is mostly impossible, but it still gives an unbiased estimate, if the number of generated samples is high enough.</p>

<p>To generate a set of dependent weights θi a Markov chain can be utilized that has
the posterior \(p(\boldsymbol{\theta}|\mathbf{X},\mathbf{y},\sigma^2)\) as its equilibrium distribution. Markov Chains are a sequence of events, where the probability of one event depends only on the state of the previous one. So, one
samples from a proposal distribution \(q(\boldsymbol{\theta}|\boldsymbol{\theta}_i)\) and maintains a record of the current state \(\boldsymbol{\theta}_i\). A Markov chain is defined by giving an initial distribution for the
first state of the chain \(\boldsymbol{\theta}_1\) and a transition distribution for a new state \(\boldsymbol{\theta}_{i+1}\) following from the current state \(\boldsymbol{\theta}_i\). A stationary distribution q is established if the distribution
given by state \(\boldsymbol{\theta}_{i+1}\) is the same as with state \(\boldsymbol{\theta}_i\). If the drawn samples are dependent then early drawn samples need to be discarded, since they usually are not representatives
of the equilibrium distribution referred to as burn in phase. If the samples are dependent
the chain also needs much longer to reach its equilibrium distribution.</p>

<p>A popular algorithm for MCMC sampling is Metropolis-Hastings. The acceptance probability Ai at time step i is given by</p>

\[A_i(\boldsymbol{\theta}_*,\boldsymbol{\theta}_i) = \textrm{min} \left( 1, \frac{q(\boldsymbol{\theta}_i|\boldsymbol{\theta}_*)\tilde{p}(\boldsymbol{\theta}_*)}{q(\boldsymbol{\theta}_*|\boldsymbol{\theta}_i)\tilde{p}(\boldsymbol{\theta}_i)}  \right) ~,\]

<p>where \(\boldsymbol{\theta}_i\) denotes the current state and \(\boldsymbol{\theta}_*\) the drawn proposal state, \(\tilde{p}(\boldsymbol{\theta})\) is the prior of the model parameters. The normalization constants cancel out each other. After the acceptance probability is calculated, a random number \(r\) is drawn from a Uniform distribution \(r \sim \mathcal{U}(0,1)\). If \(A_i &gt; r\) the proposal state is accepted.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MCMC</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">burnin_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span> <span class="o">=</span> <span class="n">num_iter</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">burnin_iter</span> <span class="o">=</span> <span class="n">burnin_iter</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">start_params</span> <span class="o">=</span> <span class="n">start_params</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">proposal_fct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scale_weights</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale_std_noise</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale_weights</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">scale_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">scale_weights</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_weights</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_std_noise</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">metropolis_hastings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">chain</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">start_params</span><span class="p">)))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">start_params</span>

        <span class="n">log_post</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
            <span class="n">proposal</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">proposal_fct</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">posterior_prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_post</span><span class="p">(</span><span class="n">proposal</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_post</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">posterior_prob</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">proposal</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">posterior_params</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">burnin_iter</span><span class="p">:].</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">posterior_params</span>

    <span class="k">def</span> <span class="nf">posterior_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">burnin_iter</span><span class="p">:]])</span>
        <span class="k">return</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">flatten</span><span class="p">()</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_scale_weights</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">prior_scale_noise</span><span class="o">=</span><span class="mf">5.</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prior_scale_weights</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">prior_scale_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">prior_scale_weights</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">log_prior_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">psw</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">psw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">prior_scale_weights</span><span class="p">)])</span>
        <span class="n">log_prior_noise</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">uniform</span><span class="p">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">prior_scale_noise</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_prior_weights</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">log_prior_noise</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="variational-inference">Variational Inference</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VI</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">start_alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">start_beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="n">alpha_a_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">alpha_b_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">beta_c_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">beta_d_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">alpha_a_prior</span> <span class="o">=</span> <span class="n">alpha_a_prior</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">alpha_b_prior</span> <span class="o">=</span> <span class="n">alpha_b_prior</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">beta_c_prior</span> <span class="o">=</span> <span class="n">beta_c_prior</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">beta_d_prior</span> <span class="o">=</span> <span class="n">beta_d_prior</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">start_alpha</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">start_beta</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span> <span class="o">=</span> <span class="n">num_iter</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pol_grad</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">pol_grad</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">D</span><span class="p">)]).</span><span class="n">transpose</span><span class="p">()</span>

        <span class="n">alpha_a</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">alpha_a_prior</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">D</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">beta_c</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">beta_c_prior</span> <span class="o">+</span> <span class="n">N</span><span class="o">/</span><span class="mi">2</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span><span class="p">)):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">*</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">D</span><span class="p">))</span>

            <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

            <span class="n">beta_d</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">beta_d_prior</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta_c</span><span class="o">/</span><span class="n">beta_d</span>

            <span class="n">alpha_b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">alpha_b_prior</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">trace</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha_a</span><span class="o">/</span><span class="n">alpha_b</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">x_var</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="p">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span>

    <span class="k">def</span> <span class="nf">posterior_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_pred</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_pred</span><span class="o">**</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">D</span><span class="p">)]).</span><span class="n">transpose</span><span class="p">()</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
            <span class="n">weight_sample</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">w_mean</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_cov</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">weight_sample</span><span class="p">[:,</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="n">preds</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">preds</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">preds</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">flatten</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_params_mcmc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">start_params</span><span class="o">=</span><span class="n">start_params_mcmc</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
<span class="n">posterior_params_mcmc</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">.</span><span class="n">metropolis_hastings</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_noisy</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 9999/9999 [00:13&lt;00:00, 730.09it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vi</span> <span class="o">=</span> <span class="n">VI</span><span class="p">()</span>
<span class="n">w_mean_vi</span><span class="p">,</span> <span class="n">w_cov_vi</span> <span class="o">=</span> <span class="n">vi</span><span class="p">.</span><span class="n">inference</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_noisy</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:00&lt;00:00, 6377.13it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">y_true_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<span class="n">y_pred_mcmc_mean</span><span class="p">,</span> <span class="n">y_pred_mcmc_std</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">.</span><span class="n">posterior_pred</span><span class="p">(</span><span class="n">x_pred</span><span class="p">)</span>
<span class="n">y_pred_vi_mean</span><span class="p">,</span> <span class="n">y_pred_vi_std</span> <span class="o">=</span> <span class="n">vi</span><span class="p">.</span><span class="n">posterior_pred</span><span class="p">(</span><span class="n">x_pred</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_true_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'true'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred_vi_mean</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'VI'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred_vi_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_pred_vi_std</span><span class="p">,</span> <span class="n">y_pred_vi_mean</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_pred_vi_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred_mcmc_mean</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'MCMC'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#D1895C'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred_mcmc_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_pred_mcmc_std</span><span class="p">,</span> <span class="n">y_pred_mcmc_mean</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_pred_mcmc_std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#D1895C'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_noisy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">r'$$x$$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">17</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">r'$$y$$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">17</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'reg_mcmc_vi.png'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/imgs/compare_mcmc_vi_files/compare_mcmc_vi_10_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mcmc</span><span class="p">.</span><span class="n">chain</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
    <span class="c1"># mcmc
</span>    <span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">.</span><span class="n">chain</span><span class="p">[</span><span class="n">mcmc</span><span class="p">.</span><span class="n">burnin_iter</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span><span class="n">i</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">samples</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">samples</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>

    <span class="n">mu_mcmc</span><span class="p">,</span> <span class="n">std_mcmc</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="c1">#ax.hist(x, bins=20)
</span>    <span class="c1">#ax.plot(x, stats.norm.pdf(x, mu_mcmc, std_mcmc), label='mcmc', color='#D1895C')
</span>    <span class="c1">#ax.axvline(x.mean(), color='#D1895C', linestyle='--', linewidth=2, label='mean')
</span>
    <span class="c1"># true params
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="c1"># mcmc
</span>        <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_mcmc</span><span class="p">,</span> <span class="n">std_mcmc</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'mcmc'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#D1895C'</span><span class="p">)</span>
        <span class="c1"># vi
</span>        <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">vi</span><span class="p">.</span><span class="n">w_mean</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">vi</span><span class="p">.</span><span class="n">w_cov</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="p">]),</span> <span class="n">label</span><span class="o">=</span><span class="s">'vi'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'true'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="n">set_text</span><span class="p">(</span><span class="s">r'posterior -- $$w_%d$$'</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">vi_std_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vi</span><span class="p">.</span><span class="n">x_var</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">vi_std_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vi</span><span class="p">.</span><span class="n">x_var</span><span class="p">).</span><span class="n">std</span><span class="p">()</span>
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">vi_std_mean</span><span class="o">+</span><span class="mf">3.5</span><span class="o">*</span><span class="n">vi_std_std</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="c1"># mcmc
</span>        <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">mu_mcmc</span><span class="p">,</span> <span class="n">std_mcmc</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'mcmc'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#D1895C'</span><span class="p">)</span>
        <span class="c1"># vi
</span>        <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">vi_std_mean</span><span class="p">,</span> <span class="n">vi_std_std</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'vi'</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">std_noise</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'true'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="n">set_text</span><span class="p">(</span><span class="s">r'posterior -- $$\sigma_{noise}$$'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/imgs/compare_mcmc_vi_files/compare_mcmc_vi_11_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

  </div><a class="u-url" href="/linear/regression/vi/mcmc/2020/11/14/compare_mcmc_vi.html" hidden></a>
</article>
<div class="footer">
 <div class="cookie-warning">
  <h1>Cookie Warning</h1>
  <p>I hereby have to draw your intention to the fact that this site uses cookies for a better interaction with this site. Nothing is saved for advertising.</p>
  <div class="cookie-btns">
   <input type="button" value="Got it" id="cookie-yes" />
   <input type="button" value="No thanks" id="cookie-no" />
  </div>
 </div>
 <div class="footer-personal">
  <h2>Malte Tölle</h2>
  <p>Machine Learning and Computer Vision</p>
 </div>
 <div class="footer-links">
 <a href="mailto:malte.toelle@gmail.com" ><img src="/assets/imgs/mail.svg" class="footer-social-media" /></a>
 <a href="/assets//pdfs/CV.pdf" ><img src="/assets/imgs/cv.svg" class="footer-social-media" /></a>
 <a href="https://github.com/maltetoelle" ><img src="/assets/imgs/github.svg" class="footer-social-media" /></a>
 <a href="https://www.linkedin.com/in/malte-t%C3%B6lle-96439b1a0/" ><img src="/assets/imgs/linkedin.svg" class="footer-social-media" /></a>
</div>

</div>


       </div>
      </div>

    </main><div class="footer">
 <div class="cookie-warning">
  <h1>Cookie Warning</h1>
  <p>I hereby have to draw your intention to the fact that this site uses cookies for a better interaction with this site. Nothing is saved for advertising.</p>
  <div class="cookie-btns">
   <input type="button" value="Got it" id="cookie-yes" />
   <input type="button" value="No thanks" id="cookie-no" />
  </div>
 </div>
 <div class="footer-personal">
  <h2>Malte Tölle</h2>
  <p>Machine Learning and Computer Vision</p>
 </div>
 <div class="footer-links">
 <a href="mailto:malte.toelle@gmail.com" ><img src="/assets/imgs/mail.svg" class="footer-social-media" /></a>
 <a href="/assets//pdfs/CV.pdf" ><img src="/assets/imgs/cv.svg" class="footer-social-media" /></a>
 <a href="https://github.com/maltetoelle" ><img src="/assets/imgs/github.svg" class="footer-social-media" /></a>
 <a href="https://www.linkedin.com/in/malte-t%C3%B6lle-96439b1a0/" ><img src="/assets/imgs/linkedin.svg" class="footer-social-media" /></a>
</div>

</div>
<script src="https://cdn.jsdelivr.net/npm/js-cookie@rc/dist/js.cookie.min.js"></script>
  <script src="/assets/js/script.js" ></script>
  </body>

</html>
